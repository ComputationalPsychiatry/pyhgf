\section{Open Questions and Issues}

\begin{itemize}
	\item To Do: 
	\begin{itemize}
		\item Visualize the network of nodes and their connections resulting from the continuous time equations.
		\item Implement these differential equations, examine the stability of the network and present exemplary simulations. 
	\end{itemize}
	
	\item Equations: The coupling parameters $\alpha$ and $\kappa$ must be available to both the connection between a node's \textsf{PE unit} and the parent's \textsf{UPDATE unit}, as well as the connection between a node's \textsf{PREDICTION unit} and the parent's \textsf{UPDATE unit}. How can it be ensured that the coupling strength is the same for both connections? For this question we would actually have to consider the learning or update equations for the parameters of the model (see for example the approach in \cite{Bogacz2017}). However, even without writing them down, we could assume that under 'healthy' conditions, the weights of these different connections automatically converge to the same (or at least very similar) values. This opens up new possibilities of modeling abnormal inference: Using the simulations presented above, we could find out how an agent's inference would be altered if these values were not the same, and what range of difference would actually lead to observable changes in the inference. 

	\item Implementation: To whom does the knowledge about parameters, in particular coupling strengths, belong? Ideally, this would belong to the connections themselves and be accessible to both child and parent node. However, in terms of synaptic signalling, how can a node have direct access to a coupling strength other than via the signalled value (which is the product of the coupling strength and the signal)?

	\item Not covered here: Computations of input nodes and binary input nodes.
\end{itemize}